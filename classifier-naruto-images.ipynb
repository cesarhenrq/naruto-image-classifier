{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1dxFu3V4nUPKdpv4xO5fzj5JJBBBndWVV","timestamp":1666722432333}],"collapsed_sections":[],"authorship_tag":"ABX9TyNx4ak81vxu616Qb9PHMu6M"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Projeto de Transfer Learning para classificar personagens do Naruto"],"metadata":{"id":"q6a5udfrI2Ka"}},{"cell_type":"markdown","source":["Iremos usar o VGG16 para classificar imagens dos personagens de Naruto. \n","\n","As imagens foram obtidas do repositório: https://github.com/Osunadev/naruto-character-classification. Lá existem 300 imagens divididas em 10 personagens.\n","\n","Primeiro vamos carregar o VGG16 e remover sua camada final, a camada de classificação softmax de 1000 classes específica para ImageNet, e substituí-la por uma nova camada de classificação para as classes sobre as quais estamos treinando. Em seguida, congelaremos todos os pesos na rede, exceto os novos que se conectam à nova camada de classificação, e treinaremos a nova camada de classificação sobre nosso novo conjunto de dados."],"metadata":{"id":"AqTAugzKJo1-"}},{"cell_type":"code","source":["%matplotlib inline\n","\n","import os\n","\n","import random\n","import numpy as np\n","import keras\n","\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import imshow\n","\n","from keras.preprocessing import image\n","from keras.applications.imagenet_utils import preprocess_input\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Activation\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.models import Model"],"metadata":{"id":"hnk9d_TwJDhd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tensor-flow backend"],"metadata":{"id":"29V90ij-OzRe"}},{"cell_type":"code","source":["hroot = 'Naruto_images'\n","\n","train_split, val_split = 0.7, 0.15\n","\n","categories = [x[0] for x in os.walk(root) if x[0]][1:]\n","categories = [c for c in categories if c not in [os.path.join(root, e) for e in exclude]]\n","\n","print(categories)"],"metadata":{"id":"kPjapjx6P1aE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carregamento do banco de imagens do Naruto"],"metadata":{"id":"xM1yiX2vSc-H"}},{"cell_type":"code","source":["# helper function to load image and return it and input vector\n","def get_image(path):\n","    img = image.load_img(path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    return img, x"],"metadata":{"id":"PyOqGubrS8qC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["A função acima é para pré-processar a imagem"],"metadata":{"id":"x1o3JzlbTC8_"}},{"cell_type":"code","source":["data = []\n","for c, category in enumerate(categories):\n","    images = [os.path.join(dp, f) for dp, dn, filenames \n","              in os.walk(category) for f in filenames \n","              if os.path.splitext(f)[1].lower() in ['.jpg','.png','.jpeg']]\n","    for img_path in images:\n","        img, x = get_image(img_path)\n","        data.append({'x':np.array(x[0]), 'y':c})\n","\n","# count the number of classes\n","num_classes = len(categories)"],"metadata":{"id":"Bqn11NV8TVKN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carrega todas as imagens da pasta root"],"metadata":{"id":"ZvzHjw__Tk0x"}},{"cell_type":"code","source":["random.shuffle(data)"],"metadata":{"id":"UOjdUXDFTy17"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Randomiza a ordem dos dados"],"metadata":{"id":"E3BJcJxiTzmh"}},{"cell_type":"code","source":["idx_val = int(train_split * len(data))\n","idx_test = int((train_split + val_split) * len(data))\n","train = data[:idx_val]\n","val = data[idx_val:idx_test]\n","test = data[idx_test:]"],"metadata":{"id":"A1bmPLw_T2k5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cria training / validation / test split (70%, 15%, 15%)"],"metadata":{"id":"w53BKGdxUEaf"}},{"cell_type":"code","source":["x_train, y_train = np.array([t[\"x\"] for t in train]), [t[\"y\"] for t in train]\n","x_val, y_val = np.array([t[\"x\"] for t in val]), [t[\"y\"] for t in val]\n","x_test, y_test = np.array([t[\"x\"] for t in test]), [t[\"y\"] for t in test]\n","print(y_test)"],"metadata":{"id":"PXqY8MQFUNTg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Separa as dados das labels"],"metadata":{"id":"0IVOhIbkUd3l"}},{"cell_type":"code","source":["# normalize data\n","x_train = x_train.astype('float32') / 255.\n","x_val = x_val.astype('float32') / 255.\n","x_test = x_test.astype('float32') / 255.\n","\n","# convert labels to one-hot vectors\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_val = keras.utils.to_categorical(y_val, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","print(y_test.shape)"],"metadata":{"id":"tYYYyLzfUzCK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pré-processamento dos dados como antes, certificando-se de que sejam float32 e normalizados entre 0 e 1."],"metadata":{"id":"7kcV1f28VOAy"}},{"cell_type":"markdown","source":[],"metadata":{"id":"dOR6NrGSUz4f"}},{"cell_type":"code","source":["\n","vgg = keras.applications.VGG16(weights='imagenet', include_top=True)\n","vgg.summary()"],"metadata":{"id":"VQ8o8YA4V3hR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Carremento do VGG16 do Keras e uma impressão do sumário. Note o tamanho da rede neural."],"metadata":{"id":"47uf5IytWGRY"}},{"cell_type":"code","source":["# make a reference to VGG's input layer\n","inp = vgg.input\n","\n","# make a new softmax layer with num_classes neurons\n","new_classification_layer = Dense(num_classes, activation='softmax')\n","\n","# connect our new layer to the second to last layer in VGG, and make a reference to it\n","out = new_classification_layer(vgg.layers[-2].output)\n","\n","# create a new network between inp and out\n","model_new = Model(inp, out)"],"metadata":{"id":"do8htJ62WcbZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Aqui aplicamos a mudança no VGG16 que dizemos que ia aplicar."],"metadata":{"id":"hm1XhpDeWdg9"}},{"cell_type":"code","source":["# make all layers untrainable by freezing weights (except for last layer)\n","for l, layer in enumerate(model_new.layers[:-1]):\n","    layer.trainable = False\n","\n","# ensure the last layer is trainable/not frozen\n","for l, layer in enumerate(model_new.layers[-1:]):\n","    layer.trainable = True\n","\n","model_new.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])\n","\n","model_new.summary()"],"metadata":{"id":"QkMAMBMLW8tq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Vamos treinar novamente essa rede, model_new no novo conjunto de dados e rótulos. Mas primeiro, precisamos congelar os pesos e desvios em todas as camadas da rede, exceto nossa nova no final, com a expectativa de que os recursos aprendidos no VGG ainda sejam bastante relevantes para a nova tarefa de classificação de imagens."],"metadata":{"id":"VvQ_hwGCW-hL"}},{"cell_type":"code","source":["\n","history2 = model_new.fit(x_train, y_train, \n","                         batch_size=128, \n","                         epochs=10, \n","                         validation_data=(x_val, y_val))"],"metadata":{"id":"16rNSBEpXQoh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Como antes, vamos em frente e treinamos o novo modelo, usando os mesmos hiperparâmetros (tamanho do lote e número de épocas) de antes, juntamente com o mesmo algoritmo de otimização. Também acompanhamos sua história à medida que avançamos."],"metadata":{"id":"25eMWMUcXqVf"}},{"cell_type":"code","source":["loss, accuracy = model_new.evaluate(x_test, y_test, verbose=0)\n","\n","print('Test loss:', loss)\n","print('Test accuracy:', accuracy)"],"metadata":{"id":"CIK2avCtXn-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Impressão da perda e da acurácia do modelo."],"metadata":{"id":"710XlLMDYWCL"}},{"cell_type":"code","source":["img, x = get_image('Naruto_images/Jiraya/image07.jpeg')\n","probabilities = model_new.predict([x])"],"metadata":{"id":"X_fhNp_0YTOo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Para prever uma nova imagem, basta executar o código a seguir para obter as probabilidades de cada classe."],"metadata":{"id":"eL6YNtnLZPCx"}}]}